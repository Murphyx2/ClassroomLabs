{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style=\"font-family: Arial; font-size:3em;color:black;\"> Session 5 - Lab Exercise 9</p>\n",
    "\n",
    "Students in this Group:\n",
    "- Albornoz Cambiaso, Francisco\n",
    "- Anicio Pereira Junior, Jose\n",
    "- Cespedes Acosta, Braulio Jose\n",
    "- Fernandes Lemos, Debora\n",
    "- Jami, Alimul Hasan\n",
    "- Kakkar, Himanshu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "is_executing": true
   },
   "outputs": [],
   "source": [
    "# For this example, we will use K-Means Clustering Project database from Kaggle (https://www.kaggle.com/faressayah/k-means-clustering-private-vs-public-universities)\n",
    "# We actually have the labels for this data set, but we will NOT use them for the KMeans clustering algorithm, since that is an unsupervised learning algorithm.\n",
    "# As we will shortly see, we have a data frame with 777 observations on 18 variables.\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['College', 'Private', 'Apps', 'Accept', 'Enroll', 'Top10perc',\n",
       "       'Top25perc', 'F.Undergrad', 'P.Undergrad', 'Outstate', 'Room.Board',\n",
       "       'Books', 'Personal', 'PhD', 'Terminal', 'S.F.Ratio', 'perc.alumni',\n",
       "       'Expend', 'Grad.Rate'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('College_Data')\n",
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\TUF\\AppData\\Local\\Temp\\ipykernel_2092\\2945803996.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['Grad.Rate']['Cazenovia College'] = 100\n"
     ]
    }
   ],
   "source": [
    "df['Grad.Rate']['Cazenovia College'] = 100\n",
    "#Removing college as a index column\n",
    "df = df.drop('College', axis=1)\n",
    "#Removing feature to confirm the impact in the model performance\n",
    "#df = df.drop('Top10perc', axis=1)\n",
    "#df = df.drop('Top25perc', axis=1)\n",
    "#df = df.drop('S.F.Ratio', axis=1)\n",
    "#df = df.drop('perc.alumni', axis=1)\n",
    "#df = df.drop('Grad.Rate', axis=1)\n",
    "# Try removing various columns (features) from the dataset and examine if it improves/degrades your K-Means model performance, or it may have little impact.\n",
    "# Report 10 cases where you removed one or more features and indicate how it impacted the model performance.\n",
    "# Case 0: No feature removed. Result: Without removing any feature we get an accuracy of 52%(0.52) \n",
    "# Case 1: Removed feature 'Accept'. Result: Removing Accept, decrease the accuracy to a 44%(0.44)\n",
    "# Case 2: Removed feature 'Book'. Result: Removing Book, increase  the accuracy to a 53%(0.53)\n",
    "# Case 3: Removed feature 'Book' and 'Outstate'. Result: This combination has a significant impact, reducing the accuracy to a 21%\n",
    "# Case 4: Removed feature 'Room.Board', 'Terminal', 'Personal', 'Accept' and 'PhD' . Result: Execution will result in an accuracy of 38% \n",
    "# Case 5: Removed feature 'Book', 'Terminal', 'PhD', 'Accept', 'Top10perc'. Result: Accuracy was reduced to a 19%, meaning that one or more of those feature has a significant impact in clusterization process. \n",
    "# Case 6: Removed feature 'Book', 'Terminal', restore features 'PhD', 'Accept'. Result: Removing those features has a significant negative impact in the accuracy, with a 19%\n",
    "# Case 7: Removed feature with low numeric values: [perc.alumni, S.F.Ratio, Top25perc, Top10perc]. Result: By reducing features with small weight from the dataframe, We have noticed a significant improvement in the accuracy: 80%, Although, we have observed cases where the accuracy drop to a 20%\n",
    "# Case 8: Removed features [perc.alumni, S.F.Ratio, Top25perc, Top10perc, S.F.Ratio, Grad.Rate] . Result: By removing these features It made the model unreliable, in the first run one could get 20% and in other an 80%.\n",
    "# Case 9: Removed feature 'Top10perc'. Result: Removing this feature made the model unstable, the accuracy values jump from 20% to 80% in some instances.\n",
    "# Case 10: Leaving all the features. Results: Removing feature to this model made the results unstable and unpredicatable, by leaving the features we can get a consistent 50% accuracy. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Private</th>\n",
       "      <th>Apps</th>\n",
       "      <th>Accept</th>\n",
       "      <th>Enroll</th>\n",
       "      <th>Top25perc</th>\n",
       "      <th>F.Undergrad</th>\n",
       "      <th>P.Undergrad</th>\n",
       "      <th>Outstate</th>\n",
       "      <th>Room.Board</th>\n",
       "      <th>Books</th>\n",
       "      <th>Personal</th>\n",
       "      <th>PhD</th>\n",
       "      <th>Terminal</th>\n",
       "      <th>S.F.Ratio</th>\n",
       "      <th>perc.alumni</th>\n",
       "      <th>Expend</th>\n",
       "      <th>Grad.Rate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Yes</td>\n",
       "      <td>1660</td>\n",
       "      <td>1232</td>\n",
       "      <td>721</td>\n",
       "      <td>52</td>\n",
       "      <td>2885</td>\n",
       "      <td>537</td>\n",
       "      <td>7440</td>\n",
       "      <td>3300</td>\n",
       "      <td>450</td>\n",
       "      <td>2200</td>\n",
       "      <td>70</td>\n",
       "      <td>78</td>\n",
       "      <td>18.10</td>\n",
       "      <td>12</td>\n",
       "      <td>7041</td>\n",
       "      <td>60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Yes</td>\n",
       "      <td>2186</td>\n",
       "      <td>1924</td>\n",
       "      <td>512</td>\n",
       "      <td>29</td>\n",
       "      <td>2683</td>\n",
       "      <td>1227</td>\n",
       "      <td>12280</td>\n",
       "      <td>6450</td>\n",
       "      <td>750</td>\n",
       "      <td>1500</td>\n",
       "      <td>29</td>\n",
       "      <td>30</td>\n",
       "      <td>12.20</td>\n",
       "      <td>16</td>\n",
       "      <td>10527</td>\n",
       "      <td>56</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Yes</td>\n",
       "      <td>1428</td>\n",
       "      <td>1097</td>\n",
       "      <td>336</td>\n",
       "      <td>50</td>\n",
       "      <td>1036</td>\n",
       "      <td>99</td>\n",
       "      <td>11250</td>\n",
       "      <td>3750</td>\n",
       "      <td>400</td>\n",
       "      <td>1165</td>\n",
       "      <td>53</td>\n",
       "      <td>66</td>\n",
       "      <td>12.90</td>\n",
       "      <td>30</td>\n",
       "      <td>8735</td>\n",
       "      <td>54</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Yes</td>\n",
       "      <td>417</td>\n",
       "      <td>349</td>\n",
       "      <td>137</td>\n",
       "      <td>89</td>\n",
       "      <td>510</td>\n",
       "      <td>63</td>\n",
       "      <td>12960</td>\n",
       "      <td>5450</td>\n",
       "      <td>450</td>\n",
       "      <td>875</td>\n",
       "      <td>92</td>\n",
       "      <td>97</td>\n",
       "      <td>7.70</td>\n",
       "      <td>37</td>\n",
       "      <td>19016</td>\n",
       "      <td>59</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Yes</td>\n",
       "      <td>193</td>\n",
       "      <td>146</td>\n",
       "      <td>55</td>\n",
       "      <td>44</td>\n",
       "      <td>249</td>\n",
       "      <td>869</td>\n",
       "      <td>7560</td>\n",
       "      <td>4120</td>\n",
       "      <td>800</td>\n",
       "      <td>1500</td>\n",
       "      <td>76</td>\n",
       "      <td>72</td>\n",
       "      <td>11.90</td>\n",
       "      <td>2</td>\n",
       "      <td>10922</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Private  Apps  Accept  Enroll  Top25perc  F.Undergrad  P.Undergrad  \\\n",
       "0     Yes  1660    1232     721         52         2885          537   \n",
       "1     Yes  2186    1924     512         29         2683         1227   \n",
       "2     Yes  1428    1097     336         50         1036           99   \n",
       "3     Yes   417     349     137         89          510           63   \n",
       "4     Yes   193     146      55         44          249          869   \n",
       "\n",
       "   Outstate  Room.Board  Books  Personal  PhD  Terminal  S.F.Ratio  \\\n",
       "0      7440        3300    450      2200   70        78      18.10   \n",
       "1     12280        6450    750      1500   29        30      12.20   \n",
       "2     11250        3750    400      1165   53        66      12.90   \n",
       "3     12960        5450    450       875   92        97       7.70   \n",
       "4      7560        4120    800      1500   76        72      11.90   \n",
       "\n",
       "   perc.alumni  Expend  Grad.Rate  \n",
       "0           12    7041         60  \n",
       "1           16   10527         56  \n",
       "2           30    8735         54  \n",
       "3           37   19016         59  \n",
       "4            2   10922         15  "
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Apps</th>\n",
       "      <th>Accept</th>\n",
       "      <th>Enroll</th>\n",
       "      <th>Top25perc</th>\n",
       "      <th>F.Undergrad</th>\n",
       "      <th>P.Undergrad</th>\n",
       "      <th>Outstate</th>\n",
       "      <th>Room.Board</th>\n",
       "      <th>Books</th>\n",
       "      <th>Personal</th>\n",
       "      <th>PhD</th>\n",
       "      <th>Terminal</th>\n",
       "      <th>S.F.Ratio</th>\n",
       "      <th>perc.alumni</th>\n",
       "      <th>Expend</th>\n",
       "      <th>Grad.Rate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>777.00</td>\n",
       "      <td>777.00</td>\n",
       "      <td>777.00</td>\n",
       "      <td>777.00</td>\n",
       "      <td>777.00</td>\n",
       "      <td>777.00</td>\n",
       "      <td>777.00</td>\n",
       "      <td>777.00</td>\n",
       "      <td>777.00</td>\n",
       "      <td>777.00</td>\n",
       "      <td>777.00</td>\n",
       "      <td>777.00</td>\n",
       "      <td>777.00</td>\n",
       "      <td>777.00</td>\n",
       "      <td>777.00</td>\n",
       "      <td>777.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>3001.64</td>\n",
       "      <td>2018.80</td>\n",
       "      <td>779.97</td>\n",
       "      <td>55.80</td>\n",
       "      <td>3699.91</td>\n",
       "      <td>855.30</td>\n",
       "      <td>10440.67</td>\n",
       "      <td>4357.53</td>\n",
       "      <td>549.38</td>\n",
       "      <td>1340.64</td>\n",
       "      <td>72.66</td>\n",
       "      <td>79.70</td>\n",
       "      <td>14.09</td>\n",
       "      <td>22.74</td>\n",
       "      <td>9660.17</td>\n",
       "      <td>65.46</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>3870.20</td>\n",
       "      <td>2451.11</td>\n",
       "      <td>929.18</td>\n",
       "      <td>19.80</td>\n",
       "      <td>4850.42</td>\n",
       "      <td>1522.43</td>\n",
       "      <td>4023.02</td>\n",
       "      <td>1096.70</td>\n",
       "      <td>165.11</td>\n",
       "      <td>677.07</td>\n",
       "      <td>16.33</td>\n",
       "      <td>14.72</td>\n",
       "      <td>3.96</td>\n",
       "      <td>12.39</td>\n",
       "      <td>5221.77</td>\n",
       "      <td>17.18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>81.00</td>\n",
       "      <td>72.00</td>\n",
       "      <td>35.00</td>\n",
       "      <td>9.00</td>\n",
       "      <td>139.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>2340.00</td>\n",
       "      <td>1780.00</td>\n",
       "      <td>96.00</td>\n",
       "      <td>250.00</td>\n",
       "      <td>8.00</td>\n",
       "      <td>24.00</td>\n",
       "      <td>2.50</td>\n",
       "      <td>0.00</td>\n",
       "      <td>3186.00</td>\n",
       "      <td>10.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>776.00</td>\n",
       "      <td>604.00</td>\n",
       "      <td>242.00</td>\n",
       "      <td>41.00</td>\n",
       "      <td>992.00</td>\n",
       "      <td>95.00</td>\n",
       "      <td>7320.00</td>\n",
       "      <td>3597.00</td>\n",
       "      <td>470.00</td>\n",
       "      <td>850.00</td>\n",
       "      <td>62.00</td>\n",
       "      <td>71.00</td>\n",
       "      <td>11.50</td>\n",
       "      <td>13.00</td>\n",
       "      <td>6751.00</td>\n",
       "      <td>53.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>1558.00</td>\n",
       "      <td>1110.00</td>\n",
       "      <td>434.00</td>\n",
       "      <td>54.00</td>\n",
       "      <td>1707.00</td>\n",
       "      <td>353.00</td>\n",
       "      <td>9990.00</td>\n",
       "      <td>4200.00</td>\n",
       "      <td>500.00</td>\n",
       "      <td>1200.00</td>\n",
       "      <td>75.00</td>\n",
       "      <td>82.00</td>\n",
       "      <td>13.60</td>\n",
       "      <td>21.00</td>\n",
       "      <td>8377.00</td>\n",
       "      <td>65.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>3624.00</td>\n",
       "      <td>2424.00</td>\n",
       "      <td>902.00</td>\n",
       "      <td>69.00</td>\n",
       "      <td>4005.00</td>\n",
       "      <td>967.00</td>\n",
       "      <td>12925.00</td>\n",
       "      <td>5050.00</td>\n",
       "      <td>600.00</td>\n",
       "      <td>1700.00</td>\n",
       "      <td>85.00</td>\n",
       "      <td>92.00</td>\n",
       "      <td>16.50</td>\n",
       "      <td>31.00</td>\n",
       "      <td>10830.00</td>\n",
       "      <td>78.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>48094.00</td>\n",
       "      <td>26330.00</td>\n",
       "      <td>6392.00</td>\n",
       "      <td>100.00</td>\n",
       "      <td>31643.00</td>\n",
       "      <td>21836.00</td>\n",
       "      <td>21700.00</td>\n",
       "      <td>8124.00</td>\n",
       "      <td>2340.00</td>\n",
       "      <td>6800.00</td>\n",
       "      <td>103.00</td>\n",
       "      <td>100.00</td>\n",
       "      <td>39.80</td>\n",
       "      <td>64.00</td>\n",
       "      <td>56233.00</td>\n",
       "      <td>118.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Apps   Accept  Enroll  Top25perc  F.Undergrad  P.Undergrad  \\\n",
       "count   777.00   777.00  777.00     777.00       777.00       777.00   \n",
       "mean   3001.64  2018.80  779.97      55.80      3699.91       855.30   \n",
       "std    3870.20  2451.11  929.18      19.80      4850.42      1522.43   \n",
       "min      81.00    72.00   35.00       9.00       139.00         1.00   \n",
       "25%     776.00   604.00  242.00      41.00       992.00        95.00   \n",
       "50%    1558.00  1110.00  434.00      54.00      1707.00       353.00   \n",
       "75%    3624.00  2424.00  902.00      69.00      4005.00       967.00   \n",
       "max   48094.00 26330.00 6392.00     100.00     31643.00     21836.00   \n",
       "\n",
       "       Outstate  Room.Board   Books  Personal    PhD  Terminal  S.F.Ratio  \\\n",
       "count    777.00      777.00  777.00    777.00 777.00    777.00     777.00   \n",
       "mean   10440.67     4357.53  549.38   1340.64  72.66     79.70      14.09   \n",
       "std     4023.02     1096.70  165.11    677.07  16.33     14.72       3.96   \n",
       "min     2340.00     1780.00   96.00    250.00   8.00     24.00       2.50   \n",
       "25%     7320.00     3597.00  470.00    850.00  62.00     71.00      11.50   \n",
       "50%     9990.00     4200.00  500.00   1200.00  75.00     82.00      13.60   \n",
       "75%    12925.00     5050.00  600.00   1700.00  85.00     92.00      16.50   \n",
       "max    21700.00     8124.00 2340.00   6800.00 103.00    100.00      39.80   \n",
       "\n",
       "       perc.alumni   Expend  Grad.Rate  \n",
       "count       777.00   777.00     777.00  \n",
       "mean         22.74  9660.17      65.46  \n",
       "std          12.39  5221.77      17.18  \n",
       "min           0.00  3186.00      10.00  \n",
       "25%          13.00  6751.00      53.00  \n",
       "50%          21.00  8377.00      65.00  \n",
       "75%          31.00 10830.00      78.00  \n",
       "max          64.00 56233.00     118.00  "
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.set_option('display.float', '{:.2f}'.format)\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "kmeans = KMeans(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Developments\\Python\\Math\\pythonProject\\.venv\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1416: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  super()._check_params_vs_input(X, default_n_init=10)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-9 {color: black;}#sk-container-id-9 pre{padding: 0;}#sk-container-id-9 div.sk-toggleable {background-color: white;}#sk-container-id-9 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-9 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-9 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-9 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-9 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-9 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-9 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-9 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-9 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-9 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-9 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-9 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-9 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-9 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-9 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-9 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-9 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-9 div.sk-item {position: relative;z-index: 1;}#sk-container-id-9 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-9 div.sk-item::before, #sk-container-id-9 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-9 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-9 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-9 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-9 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-9 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-9 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-9 div.sk-label-container {text-align: center;}#sk-container-id-9 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-9 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-9\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>KMeans(n_clusters=2)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-9\" type=\"checkbox\" checked><label for=\"sk-estimator-id-9\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">KMeans</label><div class=\"sk-toggleable__content\"><pre>KMeans(n_clusters=2)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "KMeans(n_clusters=2)"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kmeans.fit(df.drop('Private', axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Private'] = df.Private.astype(\"category\").cat.codes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0,\n",
       "       1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1,\n",
       "       1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1,\n",
       "       0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0,\n",
       "       1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 0, 1, 0, 1, 1, 1, 1, 0, 1,\n",
       "       1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1,\n",
       "       0, 0, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 1,\n",
       "       1, 1, 1, 0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 1, 1, 1, 1, 0, 0, 1, 0, 0,\n",
       "       1, 1, 0, 1, 0, 1, 1, 1, 1, 0, 1, 0, 1, 0, 0, 1, 1, 1, 1, 0, 1, 1,\n",
       "       0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 0, 0, 0, 1, 1, 1, 1,\n",
       "       1, 0, 1, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 1, 1,\n",
       "       1, 1, 1, 1, 0, 1, 0, 0, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1,\n",
       "       1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 0, 1])"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kmeans.labels_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-0.28071654 -0.30541441 -0.33544463 -0.054861   -0.34312881 -0.23178088\n",
      "   0.08598096  0.03022996 -0.04208633 -0.14459703 -0.10783599 -0.10723275\n",
      "  -0.09619221  0.10228305  0.00904708  0.05837137]\n",
      " [ 1.64952019  1.79464753  1.97110826  0.32236904  2.01626134  1.36196909\n",
      "  -0.50523325 -0.17763446  0.24730373  0.84966752  0.63365571  0.630111\n",
      "   0.56523563 -0.60102609 -0.05316162 -0.34299635]]\n",
      "0.16602316602316602\n",
      "[[114  98]\n",
      " [550  15]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.17      0.54      0.26       212\n",
      "           1       0.13      0.03      0.04       565\n",
      "\n",
      "    accuracy                           0.17       777\n",
      "   macro avg       0.15      0.28      0.15       777\n",
      "weighted avg       0.14      0.17      0.10       777\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Developments\\Python\\Math\\pythonProject\\.venv\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1416: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  super()._check_params_vs_input(X, default_n_init=10)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "\n",
    "scalar = StandardScaler()\n",
    "\n",
    "X = df.drop('Private', axis=1)\n",
    "y = df.Private\n",
    "\n",
    "X = scalar.fit_transform(X)\n",
    "\n",
    "kmeans = KMeans(2)\n",
    "kmeans.fit(X)\n",
    "\n",
    "print(kmeans.cluster_centers_)\n",
    "\n",
    "print(accuracy_score(y, kmeans.labels_))\n",
    "print(confusion_matrix(y, kmeans.labels_))\n",
    "print(classification_report(y, kmeans.labels_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
